{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be51a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "import random\n",
    "from itertools import combinations_with_replacement\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45456890",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- INITIALISE PATHS ----\n",
    "class pathsBib:\n",
    "    data_path = 'data/'\n",
    "    model_path = 'model/'\n",
    "    res_path = 'res/'\n",
    "\n",
    "\n",
    "def init_env():\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        datafile    :   (str) file name\n",
    "    \n",
    "    \"\"\"\n",
    "    is_init_path = init_path()\n",
    "\n",
    "    datafile = None \n",
    "\n",
    "    if is_init_path:\n",
    "        datafile = pathsBib.data_path + 'DeltasOmegasAmpl_Re280.mat'\n",
    "        print(f\"Data file: {datafile}\")\n",
    "    else:\n",
    "        print(\"ERROR: failed to initialize path!\")\n",
    "        sys.exit()\n",
    "\n",
    "    return datafile\n",
    "     \n",
    "\n",
    "def init_path():\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        is_init_path()  :   (bool) if initialisation is successful\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    is_init_path = False\n",
    "    try:\n",
    "        print(\"#\"*30)\n",
    "        print(f\"Start initialization of paths\")\n",
    "        path_list = [i for _,i in pathsBib.__dict__.items() if type(i)==str and \"/\" in i]\n",
    "        print(path_list)\n",
    "        for pth in path_list:\n",
    "            Path(pth).mkdir(exist_ok=True)\n",
    "            print(f\"INIT:\\t{pth}\\tDONE\")\n",
    "        print(\"#\"*30)\n",
    "        is_init_path = True\n",
    "    except:\n",
    "        print(f\"ERROR: failed to initialise path. Please, check setup for your path!\")\n",
    "        sys.exit()\n",
    "\n",
    "    return is_init_path\n",
    "\n",
    "\n",
    "\n",
    "#---- CREATE LIBRARY OF DMD MODES ----\n",
    "class DMD:\n",
    "    def __init__(self, datafile, n_total, n_test, f_modes, order=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            datafile    :   (str) path to the data\n",
    "            n_total     :   (int) number of samples\n",
    "            n_test      :   (int) number of test samples\n",
    "            f_modes     :   (arr) frequencies of robust DMD modes\n",
    "            order       :   (int) largest order of non-linearity \n",
    "\n",
    "        \"\"\"\n",
    "        self.datafile = datafile\n",
    "\n",
    "        self.n_total = n_total\n",
    "        self.n_test = n_test\n",
    "        self.n_train = self.n_total - self.n_test # number of training samples\n",
    "\n",
    "        self.f_modes = f_modes\n",
    "        self.n_modes = len(self.f_modes) \n",
    "\n",
    "        self.order = order\n",
    "\n",
    "        self.casename = f'DMD_ntest{self.n_test}_nmodes{self.n_modes}'\n",
    "        self.filename = pathsBib.res_path + self.casename\n",
    "\n",
    "        print(f\"DMD file name:\\n {self.filename}\")\n",
    "\n",
    "\n",
    "    def load_data(self):\n",
    "        f = sio.loadmat(self.datafile)\n",
    "        list(f.keys())\n",
    "\n",
    "        data = f['DeltasOmegasAmpl']\n",
    "        self.deltas = data[:, 0] \n",
    "        self.omegas = data[:, 1]\n",
    "\n",
    "\n",
    "    def search_robust_modes(self, eps=1e-2):\n",
    "        \"\"\"\n",
    "        Search robust frequencies in the data\n",
    "\n",
    "        Args:\n",
    "            eps     :   (float) tolerance for frequency matching\n",
    "        \n",
    "        \"\"\"\n",
    "        n_ind = []\n",
    "        for i in self.f_modes:\n",
    "            ind = np.where((np.abs(self.omegas) < i + eps) & (abs(self.omegas) > i - eps))[0]\n",
    "            if len(ind) == 2: # must have a conjugate pair\n",
    "                n_ind.append(ind) \n",
    "            else:\n",
    "                print(f'WARNING: frequency {i} was not found, check value and/or tolerance and/or data!')\n",
    "        \n",
    "        n_ind = np.concatenate(n_ind) \n",
    "\n",
    "        # Truncate 'deltas' and 'omegas' \n",
    "        self.n_deltas = self.deltas[n_ind]\n",
    "        self.n_omegas = self.omegas[n_ind]\n",
    "        print(f'Found {len(self.n_omegas)} robust modes with frequencies: {self.n_omegas}')\n",
    "\n",
    "\n",
    "    def reconst_exp(self, delta, omega, t, t0=0, delta_null=True):\n",
    "        \"\"\"\n",
    "        Reconstruct exponential function for each DMD mode\n",
    "\n",
    "        Args:\n",
    "            delta       :   (float) growth rate\n",
    "            omega       :   (float) frequency\n",
    "            t           :   (float) instantaneous time\n",
    "            t0          :   (float) initial time \n",
    "\n",
    "        \"\"\"\n",
    "        if delta_null:\n",
    "            delta = 0\n",
    "\n",
    "        return np.exp((delta + 1j * omega) * (t - t0))\n",
    "\n",
    "\n",
    "    def make_library(self, dt, delta_null=True):\n",
    "        \"\"\"\n",
    "        Create library of robust modes \n",
    "\n",
    "        Args:\n",
    "            dt          :   (float) time step \n",
    "            delta_null  :   (bool) if True, set delta to zero \n",
    "        \n",
    "        \"\"\"\n",
    "        self.tt = np.arange(0, self.n_total * dt, dt) \n",
    "\n",
    "        self.library = np.zeros((len(self.n_omegas) // 2, len(self.tt)), dtype='complex') \n",
    "        for k in range(len(self.tt)):\n",
    "            for m in range(len(self.n_omegas) // 2):\n",
    "                self.library[m, k] = DMD.reconst_exp(self.n_deltas[2 * m], self.n_omegas[2 * m], self.tt[k], t0=0, delta_null=delta_null) + \\\n",
    "                                     DMD.reconst_exp(self.n_deltas[2 * m + 1], self.n_omegas[2 * m + 1], self.tt[k], t0=0, delta_null=delta_null) # add the complex conjugate\n",
    "\n",
    "        self.library = self.library.real # take only the real part\n",
    "        \n",
    "\n",
    "    def compute_nonlinear(self, remove_duplicates=True):\n",
    "        \"\"\"\n",
    "        Add non-linear combinations of modes to the library (if applicable)\n",
    "\n",
    "        Args:\n",
    "            remove_duplicates   :   (bool) if True, remove duplicated modes\n",
    "\n",
    "        Returns:\n",
    "            n_lib               :   (int) number of unique modes         \n",
    "        \n",
    "        \"\"\"\n",
    "        print('Largest order of non-linear interactions:', self.order)\n",
    "        self.order_list = list(range(2, self.order + 1))\n",
    "\n",
    "        nl_combs = 0\n",
    "        for i in self.order_list:\n",
    "            nl_combs += math.factorial(self.n_modes + i - 1) // (math.factorial(i) * math.factorial(self.n_modes - 1)) # number of distinct combinations\n",
    "        print('Number of non-linear modes:', nl_combs)\n",
    "\n",
    "        nl_library = np.zeros((nl_combs, self.n_total)) \n",
    "        count = 0\n",
    "        for what_order in self.order_list:\n",
    "            print(f'Computing non-linear modes of order {what_order}')\n",
    "            for i, comb in enumerate(combinations_with_replacement(range(self.n_modes), what_order)):\n",
    "                print(f'Mode combination {comb}')\n",
    "                nl_library[count, :] = np.prod(self.library[list(comb), :], axis=0)\n",
    "                count += 1\n",
    "\n",
    "        # Concatenate with linear modes\n",
    "        self.library = np.concatenate((self.library, nl_library), axis=0)\n",
    "        print(f'Library shape: {self.library.shape}')\n",
    "\n",
    "        self.index_list = np.arange(self.library.shape[0]) # list of unique indices\n",
    "        # Remove duplicates\n",
    "        if remove_duplicates:\n",
    "            count = 0\n",
    "            for i in self.index_list[:-1]: \n",
    "                count += 1\n",
    "                for j in self.index_list[count:]: \n",
    "                    # Scale modes (min-max)\n",
    "                    M = (self.library[i, :] - np.min(self.library[i, :])) / (np.max(self.library[i, :]) - np.min(self.library[i, :]))\n",
    "                    N = (self.library[j, :] - np.min(self.library[j, :])) / (np.max(self.library[j, :]) - np.min(self.library[j, :]))\n",
    "                    # Compute mean absolute error (MAE)\n",
    "                    MAE = np.mean(np.abs(M - N))\n",
    "                    print(f'Comparing modes M{i+1} and M{j+1}, MAE = {MAE:.4f}')\n",
    "                    if MAE < 1e-1:             \n",
    "                        print(f'Duplicate found: M{i+1} and M{j+1}, removing M{j+1}')\n",
    "                        self.index_list = np.delete(self.index_list, j)\n",
    "\n",
    "        self.library = self.library[self.index_list, :] \n",
    "        n_lib = self.library.shape[0] # number of unique modes\n",
    "        print(f'Unique library shape: {self.library.shape}')\n",
    "\n",
    "        # Split training and testing data\n",
    "        train_data = self.library[:, :self.n_train]\n",
    "        test_data = self.library[:, self.n_train:]\n",
    "        print(f'Train data shape: {train_data.shape}')\n",
    "        print(f'Test data shape: {test_data.shape}')\n",
    "        \n",
    "        # Save data\n",
    "        f = h5py.File(pathsBib.data_path + 'DMD_library_Re280.h5py', 'w')\n",
    "        f.create_dataset('train', data=train_data)\n",
    "        f.create_dataset('test', data=test_data)\n",
    "\n",
    "        return n_lib\n",
    "            \n",
    "    \n",
    "    def plot_library(self):\n",
    "        # Create labels for non-linear modes\n",
    "        labels = []\n",
    "        for what_order in self.order_list:\n",
    "            for i, comb in enumerate(combinations_with_replacement(range(self.n_modes), what_order)):\n",
    "                # Adapt to the order of modes\n",
    "                label = 'M' + 'M'.join([str(x + 1) for x in sorted(comb)])\n",
    "                labels.append(label)\n",
    "        \n",
    "        # Add linear modes at the beginning of the list\n",
    "        for i in range(self.n_modes):\n",
    "            labels.insert(i, f'M{i + 1}')\n",
    "        labels = [labels[i] for i in self.index_list] # reorder labels\n",
    "        print(f'Labels: {labels}')\n",
    "\n",
    "        fig, axs = plt.subplots(self.library.shape[0], 1, figsize=[20, self.library.shape[0]], sharex=True)\n",
    "        for i, ax in enumerate(axs):\n",
    "            ax.plot(self.tt, self.library[i, :], color='black', linestyle='-', linewidth=1)\n",
    "            ax.set_xlim([0, np.max(self.tt)])\n",
    "            ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "            ax.set_ylabel(labels[i], fontsize=10)\n",
    "\n",
    "        axs[-1].set_xlabel(rf'$t$', fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "\n",
    "\n",
    "#---- MAKE DATALOADER ----\n",
    "class dataclass:\n",
    "    def __init__(self, input_len, output_len, batch_size, train_split, scaling):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_len       :   (int) length of input sequence\n",
    "            output_len      :   (int) length of output sequence\n",
    "            batch_size      :   (int) batch size\n",
    "            train_split     :   (float) ratio of train and validation split (if 1, no validation)\n",
    "            scaling         :   (str) type of scaling (minmax, standard)\n",
    "\n",
    "        \"\"\"\n",
    "        self.input_len = input_len\n",
    "        self.output_len = output_len\n",
    "        self.batch_size = batch_size\n",
    "        self.train_split = train_split\n",
    "        self.scaling = scaling\n",
    "\n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        Create Dataloader for training and validation (if applicable)\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            f = h5py.File(pathsBib.data_path + 'DMD_library_Re280.h5py', 'r')\n",
    "            data = np.array(f['train'])\n",
    "            f.close()\n",
    "            if self.scaling:\n",
    "                data_norm = dataclass.normalise(data, self.scaling, 'enc')     \n",
    "            target = np.loadtxt(pathsBib.data_path + 'TKE_Re280.txt')\n",
    "            target = target[:data.shape[1]] # length should match training data!\n",
    "            if self.scaling:\n",
    "                target_norm = dataclass.normalise(target, self.scaling, 'dec')\n",
    "        except:\n",
    "            print(f\"ERROR: failed to find data. Please, check path or file!\")\n",
    "            sys.exit()\n",
    "        \n",
    "        X, Y = dataclass.make_Sequence(self, data=data_norm, target=target_norm)\n",
    "        self.train_dl, self.val_dl = dataclass.make_Dataloader(torch.from_numpy(X), torch.from_numpy(Y),\n",
    "                                                    batch_size=self.batch_size,\n",
    "                                                    drop_last=False,\n",
    "                                                    train_split=self.train_split)\n",
    "        print(f\"INFO: DataLoader has been generated!\")\n",
    "        del data, data_norm, target, target_norm, X, Y\n",
    "        return self.train_dl, self.val_dl\n",
    "\n",
    "\n",
    "    def make_Sequence(self, data, target):\n",
    "        \"\"\"\n",
    "        Generate time-delay sequence data\n",
    "\n",
    "        Returns:\n",
    "            X   :   (arr) Encoder data\n",
    "            Y   :   (arr) Decoder (labeled) data\n",
    "\n",
    "        \"\"\"\n",
    "        if len(data.shape) <=2:\n",
    "            data = np.expand_dims(data,0)\n",
    "        if len(target.shape) <=1:\n",
    "            target = np.expand_dims(target,0)\n",
    "        nSamples = data.shape[-1] - self.input_len - self.output_len + 1\n",
    "        # Initialise return arrays\n",
    "        X = np.empty([nSamples, self.input_len, data.shape[1]])\n",
    "        Y = np.empty([nSamples, self.output_len + 1, target.shape[0]]) # add initialization decoder\n",
    "        k = 0\n",
    "        for i in tqdm(np.arange(data.shape[0])):\n",
    "            for j in np.arange(data.shape[-1] - self.input_len - self.output_len):\n",
    "                X[k] = np.transpose(data[i, :, j       :j+self.input_len]) # put sequence first for LSTM\n",
    "                Y[k] = np.expand_dims(np.transpose(target[i, j+self.input_len-1:j+self.input_len+self.output_len]), axis=-1)\n",
    "                k    = k + 1\n",
    "\n",
    "        print(f\"The training data has been generated with shape of {X.shape, Y.shape}\")\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "\n",
    "    def make_Dataloader(X, y, batch_size, drop_last=False, train_split=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            drop_last           :   (bool) if True, drop the last batch if it does not have same number of samples\n",
    "\n",
    "        Return:\n",
    "            train_dl, val_dl    :   train and validation DataLoader\n",
    "\n",
    "        \"\"\"\n",
    "        dataset = TensorDataset(X, y)\n",
    "\n",
    "        len_d = len(dataset)\n",
    "        train_size = int(train_split * len_d)\n",
    "        valid_size = len_d - train_size\n",
    "\n",
    "        train_d, val_d = random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "        train_dl = DataLoader(train_d, batch_size=batch_size, drop_last=drop_last, shuffle=True)\n",
    "        if valid_size > 0:\n",
    "            val_dl = DataLoader(val_d, batch_size=batch_size, drop_last=drop_last, shuffle=True)\n",
    "        else:\n",
    "            val_dl = None\n",
    "\n",
    "        return train_dl, val_dl\n",
    "\n",
    "\n",
    "    def normalise(data, scaling, encdec):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encdec      :   (str) 'enc' for encoder data, 'dec' for decoder data\n",
    "\n",
    "        Returns:\n",
    "            data_norm   :   (arr) normalised data\n",
    "\n",
    "        \"\"\"\n",
    "        if scaling == \"minmax\":\n",
    "            minval = np.min(data)\n",
    "            maxval = np.max(data)\n",
    "            np.save(pathsBib.data_path + f'minmax-scaling-{encdec}.npy', [minval, maxval])\n",
    "            data_norm = (data - minval) / (maxval - minval)\n",
    "        elif scaling == \"standard\":\n",
    "            meanval = np.mean(data)\n",
    "            stdval = np.std(data)\n",
    "            np.save(pathsBib.data_path + f'standard-scaling-{encdec}.npy', [meanval, stdval])\n",
    "            data_norm = (data - meanval) / stdval\n",
    "        else:\n",
    "            print(f\"ERROR: failed to normalise data. Please, check scaling type!\")\n",
    "            sys.exit()\n",
    "\n",
    "        return data_norm\n",
    "\n",
    "\n",
    "    def reverse_normalise(data, scaling, encdec):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encdec  :   (str) 'enc' for encoder data, 'dec' for decoder data\n",
    "\n",
    "        Returns:\n",
    "            data    :   (arr) non-normalised data\n",
    "\n",
    "        \"\"\"\n",
    "        if scaling == \"minmax\":\n",
    "            minval, maxval = np.load(pathsBib.data_path + f'minmax-scaling-{encdec}.npy')\n",
    "            data = data * (maxval - minval) + minval\n",
    "        elif scaling == \"standard\":\n",
    "            meanval, stdval = np.load(pathsBib.data_path + f'standard-scaling-{encdec}.npy')\n",
    "            data = data * stdval + meanval\n",
    "        else:\n",
    "            print(f\"ERROR: failed to reverse normalise data. Please, check scaling type!\")\n",
    "            sys.exit()\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "\n",
    "# ---- NETWORKS ----\n",
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, lstm_dim, num_layer=1, dropout=0.0):\n",
    "        \"\"\" \n",
    "        Encoder Long-Short Term Memory (LSTM) network\n",
    "\n",
    "        Args:\n",
    "            input_dim   :   (int) input dimension of model \n",
    "            lstm_dim    :   (int) hidden dimension of LSTM\n",
    "            num_layer   :   (int) number of LSTM layers\n",
    "            dropout     :   (float) dropout rate between LSTM layers (if num_layer > 1)\n",
    "\n",
    "        \"\"\"\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.lstm_dim = lstm_dim\n",
    "        self.num_layer = num_layer\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=self.lstm_dim, num_layers=self.num_layer, dropout=dropout, batch_first=True)\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size, device):\n",
    "        hidden = torch.zeros(self.num_layer,\n",
    "                            batch_size,\n",
    "                            self.lstm_dim).to(device)\n",
    "\n",
    "        cell  =  torch.zeros(self.num_layer,\n",
    "                            batch_size,\n",
    "                            self.lstm_dim).to(device)\n",
    "        return hidden, cell\n",
    "        \n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            output      :   (tensor) output from last layer (shape [batch_size, seq_len, hidden_dim])\n",
    "            hidden      :   (tensor) last hidden state (shape [num_layers, batch_size, hidden_dim])\n",
    "            cell        :   (tensor) last cell state (shape [num_layers, batch_size, hidden_dim])\n",
    "         \n",
    "        \"\"\"\n",
    "        hidden, cell = self.init_hidden(input_tensor.shape[0], device=input_tensor.device)\n",
    "\n",
    "        output, (hidden, cell) = self.lstm(input_tensor, (hidden.detach(), cell.detach())) \n",
    "\n",
    "        return output, hidden, cell \n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, method, hidden_dim):\n",
    "        \"\"\"\n",
    "        Compute attention weights \n",
    "\n",
    "        Args:\n",
    "            method          :   (str) type of attention ('dot', 'general', 'concat')\n",
    "            hidden_dim      :   (int) hidden dimension of LSTM\n",
    "\n",
    "        \"\"\"\n",
    "        super(Attention, self).__init__()\n",
    "        self.method = method\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(hidden_dim, hidden_dim)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "            self.other = nn.Parameter(torch.empty(1, hidden_dim))\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        if self.method == 'concat':\n",
    "            nn.init.uniform_(self.other, -0.1, 0.1)\n",
    "\n",
    "\n",
    "    def forward(self, hidden, encoder_output):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            hidden          :   (tensor) decoder hidden state, shape [batch_size, 1, hidden_dim]\n",
    "            encoder_output  :   (tensor) encoder state, shape [batch_size, seq_len, hidden_dim]\n",
    "\n",
    "        Returns:\n",
    "            attn            :   (tensor) attention weights, shape [batch_size, 1, seq_len]\n",
    "        \n",
    "        \"\"\"\n",
    "        if self.method =='dot':\n",
    "            score = torch.bmm(hidden, encoder_output.transpose(1, 2))\n",
    "        elif self.method == 'general':\n",
    "            score = self.attn(encoder_output) \n",
    "            score = torch.bmm(hidden, score.transpose(1, 2))\n",
    "        elif self.method == 'concat':\n",
    "            score = torch.tanh(self.attn(torch.cat((hidden.expand(-1, encoder_output.size(1), -1), encoder_output), dim=2))) \n",
    "            other_exp = self.other.expand(score.size(0), -1, -1)\n",
    "            score = torch.bmm(other_exp, score.transpose(1, 2))\n",
    "\n",
    "        # Normalise attention scores to weights in range 0 to 1\n",
    "        attn = nn.functional.softmax(score, dim=2)\n",
    "        \n",
    "        return attn\n",
    "            \n",
    "            \n",
    "class DecoderAttentionLSTM(nn.Module):\n",
    "    def __init__(self, output_dim, lstm_dim, mlp_dim, num_layer=1, dropout=0.0, attn_model=None, output_len=1):\n",
    "        \"\"\" \n",
    "        Decoder LSTM network with attention (if applicable)\n",
    "\n",
    "        Args:\n",
    "            output_dim      :   (int) output dimension of model\n",
    "            lstm_dim        :   (int) hidden dimension of LSTM\n",
    "            mlp_dim         :   (int) hidden dimension of MLP\n",
    "            num_layer       :   (int) number of LSTM layers\n",
    "            dropout         :   (float) dropout rate between LSTM layers (if num_layer > 1)\n",
    "            attn_model      :   (str) type of attention model ('BAH', 'L-DOT', 'L-GEN', 'L-CON')\n",
    "            output_len      :   (int) length of output sequence\n",
    "        \n",
    "        \"\"\"\n",
    "        super(DecoderAttentionLSTM, self).__init__()\n",
    "        self.lstm_hidden = lstm_dim\n",
    "        self.num_layer = num_layer\n",
    "        self.attn_model = attn_model\n",
    "        self.output_len = output_len\n",
    "\n",
    "        if attn_model is None:\n",
    "            self.lstm = nn.LSTM(input_size=output_dim, hidden_size=lstm_dim, num_layers=num_layer, dropout=dropout, batch_first=True)\n",
    "        else:\n",
    "            self.proj = nn.Linear(output_dim, lstm_dim)\n",
    "            self.lstm = nn.LSTM(input_size=lstm_dim * 2, hidden_size=lstm_dim, num_layers=num_layer, dropout=dropout, batch_first=True)\n",
    "            # Bahdanau attention\n",
    "            if attn_model == 'BAH': \n",
    "                self.attn = Attention(method='concat', hidden_dim=lstm_dim) \n",
    "            # Luong attention\n",
    "            elif attn_model == 'L-DOT' or attn_model == 'L-GEN' or attn_model == 'L-CON':\n",
    "                if attn_model == 'L-DOT':\n",
    "                    self.attn = Attention(method='dot', hidden_dim=lstm_dim)\n",
    "                elif attn_model == 'L-GEN':\n",
    "                    self.attn = Attention(method='general', hidden_dim=lstm_dim)\n",
    "                elif attn_model == 'L-CON':\n",
    "                    self.attn = Attention(method='concat', hidden_dim=lstm_dim)\n",
    "\n",
    "                self.ffn_attn = nn.Linear(lstm_dim * 2, lstm_dim) \n",
    "            else:\n",
    "                print(f\"ERROR: attention model {attn_model} is not recognized!\")\n",
    "                sys.exit()\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(lstm_dim, mlp_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_dim, lstm_dim),\n",
    "        )\n",
    "        self.out = nn.Linear(lstm_dim, output_dim)\n",
    "\n",
    "\n",
    "    def forward(self, encoder_hidden, encoder_cell, encoder_outputs, true_tensor, device, eps):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            true_tensor     :   (tensor) true values, shape [batch_size, output_len + 1, output_dim] \n",
    "            encoder_hidden  :   (tensor) encoder hidden state, shape [num_layers, batch_size, hidden_dim]\n",
    "            encoder_cell    :   (tensor) encoder cell state, shape [num_layers, batch_size, hidden_dim]\n",
    "            encoder_outputs :   (tensor) encoder outputs, shape [batch_size, input_len, hidden_dim]\n",
    "            device          :   device to run the model on\n",
    "            eps             :   (float) probability of teacher forcing (1.0 = use true data, 0.0 = use predicted data)\n",
    "\n",
    "        Returns:\n",
    "            outputs         :   (tensor) model output, shape [batch_size, output_len, output_dim]\n",
    "            attentions      :   (tensor) attention weights, shape [batch_size, output_len, input_len] \n",
    "        \n",
    "        \"\"\"\n",
    "        device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Initialise decoder\n",
    "        decoder_input = true_tensor[:, 0, :].unsqueeze(1) # initialise with last labeled data from encoder\n",
    "        decoder_hidden = encoder_hidden[-self.num_layer:, :, :] # correct if num_layer mismatch\n",
    "        decoder_cell = encoder_cell[-self.num_layer:, :, :]\n",
    "\n",
    "        # Initialise attentional hidden state\n",
    "        if self.attn_model == 'L-DOT' or self.attn_model == 'L-GEN' or self.attn_model == 'L-CON':\n",
    "            hidden_tilde = torch.zeros(encoder_outputs.size(0), 1, self.lstm_hidden).to(device) \n",
    "\n",
    "        outputs = []\n",
    "        attentions = []\n",
    "        for i in range(self.output_len):\n",
    "            if self.attn_model is None:\n",
    "                output, decoder_hidden, decoder_cell = self.forward_step(\n",
    "                        decoder_input, decoder_hidden, decoder_cell\n",
    "                    )\n",
    "            else:\n",
    "                if self.attn_model == 'BAH':\n",
    "                    output, decoder_hidden, decoder_cell, attn_weights = self.forward_step_bahdanau(\n",
    "                        decoder_input, decoder_hidden, decoder_cell, encoder_outputs\n",
    "                    )\n",
    "                elif self.attn_model == 'L-DOT' or self.attn_model == 'L-GEN' or self.attn_model == 'L-CON':\n",
    "                    output, decoder_hidden, decoder_cell, hidden_tilde, attn_weights = self.forward_step_luong(\n",
    "                        decoder_input, decoder_hidden, decoder_cell, encoder_outputs, hidden_tilde\n",
    "                    )\n",
    "                attentions.append(attn_weights)\n",
    "            outputs.append(output)\n",
    "\n",
    "            if random.random() < eps: \n",
    "                # Teacher forcing\n",
    "                decoder_input = true_tensor[:, i+1, :].unsqueeze(1)\n",
    "            else:\n",
    "                # Scheduled sampling\n",
    "                decoder_input = output.detach()\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=1) \n",
    "        if self.attn_model:\n",
    "            attentions = torch.cat(attentions, dim=1) \n",
    "\n",
    "        return outputs, attentions\n",
    "\n",
    "    \n",
    "    def forward_step(self, input_tensor, hidden_lstm, cell_lstm):\n",
    "        out_lstm, (hidden_lstm, cell_lstm) = self.lstm(input_tensor, (hidden_lstm, cell_lstm))\n",
    "\n",
    "        # Final output layer\n",
    "        out_ffn = self.mlp(out_lstm)\n",
    "        output = self.out(out_ffn)\n",
    "        return output, hidden_lstm, cell_lstm\n",
    "\n",
    "\n",
    "    def forward_step_bahdanau(self, input_tensor, hidden_lstm, cell_lstm, encoder_outputs):\n",
    "        input_tensor_proj = self.proj(input_tensor)\n",
    "\n",
    "        # Calculate attention weights from previous LSTM state and all encoder outputs\n",
    "        attn_weights = self.attn(hidden_lstm[-1].unsqueeze(1), encoder_outputs)\n",
    "        context = torch.bmm(attn_weights, encoder_outputs) # context vector\n",
    "\n",
    "        # Combine LSTM input and context vector\n",
    "        in_lstm = torch.cat((input_tensor_proj, context), dim=2)\n",
    "        out_lstm, (hidden_lstm, cell_lstm) = self.lstm(in_lstm, (hidden_lstm, cell_lstm))\n",
    "\n",
    "        # Final output layer\n",
    "        out_ffn = self.mlp(out_lstm)\n",
    "        output = self.out(out_ffn)  \n",
    "        return output, hidden_lstm, cell_lstm, attn_weights\n",
    "\n",
    "\n",
    "    def forward_step_luong(self, input_tensor, hidden_lstm, cell_lstm, encoder_outputs, hidden_tilde):\n",
    "        input_tensor_proj = self.proj(input_tensor)\n",
    "\n",
    "        # Combine LSTM input and last attentional hidden state (input-feeding)\n",
    "        in_lstm = torch.cat((input_tensor_proj, hidden_tilde), dim=2) \n",
    "        out_lstm, (hidden_lstm, cell_lstm) = self.lstm(in_lstm, (hidden_lstm, cell_lstm))\n",
    "\n",
    "        # Calculate attention weights from current LSTM state and all encoder outputs\n",
    "        attn_weights = self.attn(out_lstm, encoder_outputs)\n",
    "        context = torch.bmm(attn_weights, encoder_outputs) # context vector\n",
    "\n",
    "        # Compute the attentional hidden state\n",
    "        in_htilde = torch.cat((out_lstm, context), dim=2)\n",
    "        hidden_tilde = torch.tanh(self.ffn_attn(in_htilde))\n",
    "\n",
    "        # Final output layer\n",
    "        out_ffn = self.mlp(hidden_tilde)\n",
    "        output = self.out(out_ffn)\n",
    "        return output, hidden_lstm, cell_lstm, hidden_tilde, attn_weights\n",
    "    \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder_params, decoder_params):\n",
    "        \"\"\"\n",
    "        Sequence-to-sequence model\n",
    "\n",
    "        Args:\n",
    "            encoder_params  :   (dict) Parameters for the encoder LSTM\n",
    "            decoder_params  :   (dict) Parameters for the decoder LSTM\n",
    "\n",
    "        \"\"\"\n",
    "        super(Seq2Seq, self).__init__()\n",
    "\n",
    "        self.encoder = EncoderLSTM(input_dim=encoder_params['input_dim'], \n",
    "                                   lstm_dim=encoder_params['lstm_dim'], \n",
    "                                   num_layer=encoder_params['num_layer'], \n",
    "                                   dropout=encoder_params['dropout']\n",
    "                                   )\n",
    "        self.decoder = DecoderAttentionLSTM(output_dim=decoder_params['output_dim'], \n",
    "                                            lstm_dim=decoder_params['lstm_dim'], \n",
    "                                            mlp_dim=decoder_params['mlp_dim'],\n",
    "                                            num_layer=decoder_params['num_layer'], \n",
    "                                            dropout=decoder_params['dropout'],\n",
    "                                            attn_model=decoder_params['attn_model'], \n",
    "                                            output_len=decoder_params['output_len']\n",
    "                                            )\n",
    "        \n",
    "\n",
    "    def forward(self, input_tensor, true_tensor, device=None, eps=0.0):\n",
    "        encoder_outputs, encoder_hidden, encoder_cell = self.encoder(input_tensor)\n",
    "        outputs, attentions = self.decoder(encoder_hidden, encoder_cell, encoder_outputs, true_tensor, device, eps)\n",
    "\n",
    "        return outputs, attentions\n",
    "    \n",
    "\n",
    "\n",
    "# ---- TRAINING LOOP ----\n",
    "def train(device, model, train_dl, loss_fn, optimizer, scheduler=None, num_epoch=100, eps_huber=0.0, schsam=None, val_dl=None):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        device      :   the device for training (it) should match the model's device!)\n",
    "        model       :   the model to be trained\n",
    "        train_dl    :   dataloader for training\n",
    "        loss_fn     :   loss function     \n",
    "        optimizer   :   optimizer function\n",
    "        scheduler   :   scheduler function\n",
    "        num_epoch   :   (int) number of epochs\n",
    "        eps_huber   :   (float) threshold for Huber loss (if 0, use MSE loss)\n",
    "        schsam      :   (str) type of scheduled sampling \n",
    "        val_dl      :   Dataloader for validation (if applicable)\n",
    "\n",
    "    Returns:\n",
    "        history     :   (dict) contains training and validation (if applicable) losses\n",
    "\n",
    "    \"\"\"\n",
    "    history = {}\n",
    "    history[\"train_loss\"] = []\n",
    "\n",
    "    if val_dl:\n",
    "        history[\"val_loss\"] = []\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train() # change to training mode\n",
    "\n",
    "        loss_val = 0; num_batch = 0\n",
    "        eps_schsam = scheduled_sampling(schsam) # get probability for teacher forcing\n",
    "        for batch in tqdm(train_dl):\n",
    "            x, y = batch\n",
    "            x = x.to(device).float(); y = y.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred, _ = model(x, y, device=device, eps=eps_schsam)\n",
    "\n",
    "            if eps_huber != 0: \n",
    "                if num_batch != 0 and num_batch % (len(train_dl)-1) == 0 and epoch % 10 == 0:\n",
    "                    with torch.no_grad():\n",
    "                        e = (pred - y[:, 1:, :]).abs()\n",
    "                        frac_mae = (e > eps_huber).float().mean().item()\n",
    "                    print(f\"INFO: fraction of samples in MAE regime: {frac_mae:.3f}\")\n",
    "\n",
    "            loss = loss_fn(pred, y[:, 1:, :])\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0) # gradient clipping\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_val += loss.item()/x.shape[0]\n",
    "            num_batch += 1\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        history[\"train_loss\"].append(loss_val/num_batch)\n",
    "    \n",
    "       \n",
    "        if val_dl:\n",
    "            model.eval() # change to evaluation mode\n",
    "\n",
    "            loss_val = 0; num_batch = 0\n",
    "            for batch in (val_dl):\n",
    "                x, y = batch\n",
    "                x = x.to(device).float(); y = y.to(device).float()\n",
    "\n",
    "                pred, _ = model(x, y, device=device, eps=0.0) # no teacher \n",
    "                loss = loss_fn(pred, y[:, 1:, :]) \n",
    "\n",
    "                loss_val += loss.item()/x.shape[0]\n",
    "                num_batch += 1\n",
    "\n",
    "            history[\"val_loss\"].append(loss_val/num_batch)\n",
    "\n",
    "        train_loss = history[\"train_loss\"][-1]\n",
    "        if val_dl:\n",
    "            val_loss = history[\"val_loss\"][-1]\n",
    "            print(f\"At Epoch    = {epoch+1},\\n\"\n",
    "                  f\"Train_loss  = {train_loss},\\n\"\n",
    "                  f\"Val_loss    = {val_loss},\\n\" \n",
    "                  f\"eps_schsam  = {eps_schsam:.4f}\"       \n",
    "            )\n",
    "            if scheduler is not None:\n",
    "                print(f\"LR      = {scheduler.get_last_lr()[0]:.4e}\")\n",
    "        else:\n",
    "            print(f\"At Epoch    = {epoch+1},\\n\"\n",
    "                  f\"Train_loss  = {train_loss},\\n\"\n",
    "                  f\"eps_schsam  = {eps_schsam:.4f}\"   \n",
    "            )\n",
    "            if scheduler is not None:\n",
    "                print(f\"LR      = {scheduler.get_last_lr()[0]:.4e}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def scheduled_sampling(schsam):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "        schsam      :   (str) type of scheduled sampling ('no_teacher', 'scheduled_sampling', else teacher forcing)\n",
    "\n",
    "    Returns:\n",
    "        eps         :   (float) probability for teacher forcing \n",
    "        \n",
    "    \"\"\"\n",
    "    if schsam == 'no_teacher':\n",
    "        eps = 0.0\n",
    "    elif schsam == 'scheduled_sampling':\n",
    "        eps = 0.5\n",
    "    else: # teacher forcing \n",
    "        eps = 1.0 \n",
    "    \n",
    "    return eps\n",
    "\n",
    "\n",
    "\n",
    "# ---- TEST ----\n",
    "class testclass:\n",
    "    def __init__(self, device, input_len, n_test, input_dim, output_dim, scaling):\n",
    "        self.device = device\n",
    "        self.input_len = input_len\n",
    "        self.n_test = n_test\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.scaling = scaling\n",
    "        \n",
    "\n",
    "    def load_pretrain_model(self, encoder_params, decoder_params):\n",
    "        \"\"\"\n",
    "        Load state_dict and history of pre-trained model\n",
    "    \n",
    "        Returns:\n",
    "            stat_dict   :   learnable parameters \n",
    "            history     :   history of training\n",
    "\n",
    "        \"\"\"\n",
    "        model_path = pathsBib.model_path + f\"ADAN_statedict-history_Att-{config.decoder_params['attn_model']}\" + \".pt\"\n",
    "\n",
    "        try:\n",
    "            ckpoint = torch.load(model_path, weights_only=False, map_location=self.device)\n",
    "        except:\n",
    "            print(\"ERROR: model not found!\")\n",
    "            sys.exit()\n",
    "\n",
    "        stat_dict = ckpoint['model']\n",
    "\n",
    "        decoder_params['output_len'] = self.n_test\n",
    "        self.model = Seq2Seq(encoder_params, decoder_params)\n",
    "        self.model.load_state_dict(state_dict=stat_dict)\n",
    "        self.history = ckpoint['history']\n",
    "\n",
    "        print(f'INFO: the state dict has been loaded!')\n",
    "        print(self.model.eval)\n",
    "\n",
    "        return self.model\n",
    "\n",
    "\n",
    "    def test(self):\n",
    "        try:\n",
    "            f = h5py.File(pathsBib.data_path + 'DMD_library_Re280.h5py', 'r')\n",
    "            data = np.transpose(np.array(f['train']))\n",
    "            f.close()\n",
    "            nsamples = data.shape[0] # number of training samples\n",
    "            if self.scaling:\n",
    "                data_norm = dataclass.normalise(data, self.scaling, 'enc')\n",
    "            data_norm = data_norm[-self.input_len:, :] # get last input_len samples to initialise encoder\n",
    "            target = np.loadtxt(pathsBib.data_path + 'TKE_Re280.txt')\n",
    "            if self.scaling:\n",
    "                target_norm = dataclass.normalise(target[:nsamples], self.scaling, 'dec') # match length of training data\n",
    "            target_norm = target_norm[-1] # initialisation decoder \n",
    "        except:\n",
    "            print(f\"ERROR: failed to find data. Please, check path or file!\")\n",
    "            sys.exit()\n",
    "\n",
    "        self.model.eval()\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        print(f\"INFO: Testing model\")\n",
    "\n",
    "        input_tensor = torch.from_numpy(data_norm[None, :, :]).float().to(self.device) # [1, input_len, input_dim]\n",
    "        true_tensor = torch.from_numpy(np.expand_dims(target_norm, axis=(0, 1, 2))).float().to(self.device) # expand dims to [1, 1, output_dim]\n",
    "\n",
    "        print(f\"INFO: starting autoregressive rollout for {self.n_test} steps\")\n",
    "        if config.decoder_params['attn_model'] is None:\n",
    "            pred, _ = self.model(input_tensor, true_tensor, device=self.device, eps=0.0)\n",
    "            pred = pred.cpu().detach().numpy()\n",
    "            print(f\"INFO: Testing completed, size of predictions = {pred.shape}\")\n",
    "        else:\n",
    "            pred, attn = self.model(input_tensor, true_tensor, device=self.device, eps=0.0)\n",
    "            pred = pred.cpu().detach().numpy()\n",
    "            self.attn = attn.cpu().detach().numpy()\n",
    "            print(f\"INFO: Testing completed, size of predictions = {pred.shape}, size of attention matrix = {self.attn.shape}\")\n",
    "\n",
    "        if self.scaling:\n",
    "            self.output = dataclass.reverse_normalise(pred, self.scaling, 'dec')\n",
    "\n",
    "        # Save results\n",
    "        np.savez_compressed(\n",
    "        file = pathsBib.res_path + 'ADAN_Preds.npz',\n",
    "        out = self.output\n",
    "        )\n",
    "\n",
    "\n",
    "    def plot_loss(self):\n",
    "        \"\"\"\n",
    "        Plot training and validation (if applicable) losses\n",
    "\n",
    "        \"\"\"\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(10,4))\n",
    "\n",
    "        axs.plot(self.history[\"train_loss\"], color='blue', linestyle='-', linewidth=1.5, marker='o', markersize=5)\n",
    "        if len(self.history[\"val_loss\"]) != 0:\n",
    "            axs.plot(self.history[\"val_loss\"], color='red', linestyle='-', linewidth=1.5, marker='^', markersize=5)\n",
    "        axs.set_yscale('log')\n",
    "        axs.grid(True, which='both')\n",
    "        axs.set_xlim([-1, len(self.history[\"train_loss\"])])\n",
    "        axs.tick_params(axis='both', which='major', labelsize=14)\n",
    "        axs.set_xlabel(\"Training epoch\", fontsize=14)\n",
    "        axs.set_ylabel(\"Loss\", fontsize=14)\n",
    "\n",
    "        axs.legend([\"Train\", \"Validation\"], fontsize=14)\n",
    "\n",
    "\n",
    "    def plot_pred(self):\n",
    "        \"\"\"\n",
    "        Plot prediction\n",
    "\n",
    "        \"\"\"\n",
    "        output_toplot = np.squeeze(self.output) \n",
    "\n",
    "        try:\n",
    "            target = np.loadtxt(pathsBib.data_path + 'TKE_Re280.txt')\n",
    "            target = target[-output_toplot.shape[0]:] \n",
    "        except:\n",
    "            print(f\"ERROR: failed to find data. Please, check path or file!\")\n",
    "            sys.exit()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20, 2), sharex=True)\n",
    "\n",
    "        ax.plot(target, color='black', linestyle='-', linewidth=2, label='True')\n",
    "        ax.plot(output_toplot, color='blue', linestyle='-', linewidth=2, label='Prediction')\n",
    "        ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "        ax.set_xlabel(r\"Prediction step\",fontsize=14)\n",
    "        ax.set_ylabel(r\"TKE\", fontsize=14)\n",
    "\n",
    "        plt.legend(ncol=2, loc='upper center', fontsize=14)\n",
    "\n",
    "\n",
    "    def plot_attn(self):\n",
    "        \"\"\" \n",
    "        Plot attention matrix (if applicable)\n",
    "        \n",
    "        \"\"\"\n",
    "        # Turn into DataFrame\n",
    "        labelx = [f'T={i+1}' for i in range(self.attn.shape[1])]\n",
    "        labely = [f't={i+1}' for i in range(self.attn.shape[2])]\n",
    "        attn_df = pd.DataFrame(self.attn[0, :, :].T, index=labely, columns=labelx)\n",
    "\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(12, 4))\n",
    "        sns.heatmap(attn_df, cmap='Reds', vmin=0.0, vmax=np.max(attn_df), square=False, cbar_kws={\"shrink\": .5, 'label': 'Attention weights'})\n",
    "        axs.tick_params(axis='both', which='major', labelsize=8)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c995a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- CONFIGURATION ----\n",
    "class config:\n",
    "    n_test = 128 \n",
    "\n",
    "    input_len = 64\n",
    "    batch_size = 32\n",
    "    train_split = 0.8\n",
    "    scaling = \"standard\" # \"minmax\", \"standard\"\n",
    "\n",
    "    encoder_params = {\n",
    "    'lstm_dim'  :   128,    \n",
    "    'mlp_dim'   :   512, # dimension MLP in ResNet encoder\n",
    "    'num_layer' :   3, # number of LSTM layers or ResLSTM blocks\n",
    "    'dropout'   :   0.2, # dropout between LSTM layers (if num_layer > 1)\n",
    "    }\n",
    "\n",
    "    decoder_params = {\n",
    "    'lstm_dim'  :   128,\n",
    "    'mlp_dim'   :   512,\n",
    "    'num_layer' :   3, # must be <= encoder num_layer!\n",
    "    'dropout'   :   0.2,    \n",
    "    'attn_model':   None, # 'BAH', 'L-DOT', 'L-GEN', 'L-CON', None (no attention)\n",
    "    'output_len':   64,\n",
    "    }\n",
    "\n",
    "    eps_huber = 5e-2 # threshold for Huber loss; if 0, use MSE loss\n",
    "    lr = 1e-3\n",
    "    schlr = True # if True, use learning rate scheduler (exponential decay)\n",
    "    num_epoch = 1000\n",
    "    schsam = 'scheduled_sampling' # 'no_teacher', 'scheduled_sampling', else teacher forcing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e01ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment\n",
    "datafile = init_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e31057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create library of DMD modes\n",
    "target_tensor = np.loadtxt(pathsBib.data_path + 'TKE_Re280.txt')\n",
    "if len(target_tensor.shape) <=1:\n",
    "    target_tensor = np.expand_dims(target_tensor,0)\n",
    "    output_dim, n_total = target_tensor.shape\n",
    "\n",
    "DMD = DMD(datafile, n_total, config.n_test, np.array([1.33, 2.29, 2.66]), order=1)\n",
    "\n",
    "DMD.load_data() \n",
    "\n",
    "DMD.search_robust_modes(eps=1e-2) \n",
    "\n",
    "DMD.make_library(dt=1, delta_null=True)\n",
    "\n",
    "n_lib = DMD.compute_nonlinear(remove_duplicates=True) \n",
    "\n",
    "DMD.plot_library()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc0dd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DL = dataclass(config.input_len, config.decoder_params[\"output_len\"], config.batch_size, config.train_split, config.scaling)\n",
    "train_dl, val_dl = DL.get_data()\n",
    "print(f\"INFO: number of training batches: {len(train_dl)}\")\n",
    "if val_dl:\n",
    "    print(f\"INFO: number of validation batches: {len(val_dl)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c61876",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.encoder_params['input_dim'] = n_lib\n",
    "config.decoder_params['output_dim'] = output_dim\n",
    "if config.decoder_params['num_layer'] > config.encoder_params['num_layer']:\n",
    "    print(f\"WARNING: decoder num_layer must be smaller or equal than encoder num_layer!\")\n",
    "\n",
    "model = Seq2Seq(config.encoder_params, config.decoder_params)\n",
    "print(model)\n",
    "NumPara = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"INFO: the model has been generated, the number of parameter is {NumPara}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3febc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"INFO: the device has been assigned to {device} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e107e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.HuberLoss(delta=config.eps_huber) if config.eps_huber != 0 else nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
    "if config.schlr == True:\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "else:\n",
    "    scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2555d45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if pre-trained model exists (avoid training)\n",
    "model_path = pathsBib.model_path + f\"ADAN_statedict-history_Att-{config.decoder_params['attn_model']}\" + \".pt\"\n",
    "if not os.path.isfile(model_path):\n",
    "    print(f\"INFO: start training!\")\n",
    "    history = train(device, model, train_dl, loss_fn, optimizer, scheduler, num_epoch=config.num_epoch, eps_huber=config.eps_huber, schsam=config.schsam, val_dl=val_dl)\n",
    "    print(f\"INFO: training finished!\")\n",
    "\n",
    "    check_point = {\"model\":model.state_dict(),\n",
    "                   \"history\":history,\n",
    "                   }\n",
    "    \n",
    "    torch.save(check_point, model_path)\n",
    "    print(f\"INFO: the checkpoint has been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5f4736",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"INFO: start testing!\")\n",
    "TT = testclass(device, config.input_len, config.n_test, config.encoder_params['input_dim'] , config.decoder_params['output_dim'], config.scaling)\n",
    "\n",
    "model = TT.load_pretrain_model(config.encoder_params, config.decoder_params)\n",
    "print(f\"INFO: the model has been loaded, the number of parameter is {NumPara}\")\n",
    "\n",
    "TT.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7602ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "TT.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707a10e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TT.plot_pred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eead3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.decoder_params['attn_model'] is not None:\n",
    "    TT.plot_attn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
